#!/usr/bin/env python3

import hashlib, random, struct, time, csv, math
import pandas as pd
import argparse

# ---------------------------------
# CLI argument: number of elements
# ---------------------------------
parser = argparse.ArgumentParser(description="O(log N) Authenticated Skip List benchmark")
parser.add_argument(
    "--size", "-s",
    type=int,
    default=4096,
    help="Number of nodes to insert (e.g., 1024, 4096, 1048576)"
)
args = parser.parse_args()
N = args.size
print(f"Using N = {N} nodes")

# ---------------------------------
# Config
# ---------------------------------
BATCH_RECOMPUTE = 512
SAMPLE_EVERY = 10
RANDOM_SEED = None   # None = random, or set e.g. 1 for reproducible

# ---------------------------------
# Hash utilities
# ---------------------------------
def sha256(x: bytes) -> bytes:
    return hashlib.sha256(x).digest()

def canonical_bytes(arg):
    if isinstance(arg, int):
        data = b'\x00' if arg == 0 else arg.to_bytes((arg.bit_length() + 7) // 8, 'big')
        tag = b'I'
    elif isinstance(arg, str):
        data = arg.encode('utf-8')
        tag = b'S'
    elif isinstance(arg, bytes):
        data = arg
        tag = b'B'
    elif arg is None:
        data = b''
        tag = b'N'
    else:
        data = str(arg).encode('utf-8')
        tag = b'S'
    return tag + struct.pack('>I', len(data)) + data

# ---------------------------------
# Node class
# ---------------------------------
class Node:
    __slots__ = ('level', 'key', 'value', 'down', 'right', 'rank',
                 'label', 'leaf_hash')
    def __init__(self, level, key=None, value=None):
        self.level = level
        self.key = key
        self.value = value
        self.down = None
        self.right = None
        self.rank = 0
        self.label = None
        self.leaf_hash = None

# ---------------------------------
# Authenticated Skip List
# ---------------------------------
class AuthSkipList:
    def __init__(self, expected_size):
        # Calculate max_level based on expected size: log2(N) + small margin
        # This ensures the structure naturally grows to ~log2(N) height
        self.max_level = max(1, int(math.log2(max(expected_size, 2))) + 2) if expected_size > 0 else 8
        self.level_heads = [Node(l) for l in range(self.max_level + 1)]
        for l in range(self.max_level, 0, -1):
            self.level_heads[l].down = self.level_heads[l - 1]
        self.head = self.level_heads[self.max_level]
        self.count = 0
        self.actual_height = 0  # Track actual max level used

    def _hash_leaf(self, key, value):
        return sha256(canonical_bytes(key) + canonical_bytes(value))

    def random_level(self):
        lvl = 0
        while random.random() < 0.5 and lvl < self.max_level:
            lvl += 1
        return lvl

    # -----------------------------
    # Insert
    # -----------------------------
    def insert(self, key, value):
        prevs = [None] * (self.max_level + 1)
        node = self.head
        for l in reversed(range(self.max_level + 1)):
            while node.right and node.right.key is not None and node.right.key < key:
                node = node.right
            prevs[l] = node
            if node.down:
                node = node.down
        lvl = self.random_level()
        
        # Update actual height
        if lvl > self.actual_height:
            self.actual_height = lvl
            
        down_link = None
        for l in range(lvl + 1):
            new = Node(l, key, value)
            if l == 0:
                new.leaf_hash = self._hash_leaf(key, value)
            new.down = down_link
            new.right = prevs[l].right
            prevs[l].right = new
            down_link = new
        self.count += 1

    # -----------------------------
    # Recompute ranks + labels
    # -----------------------------
    def recompute(self):
        # Clear ranks and labels
        for l in range(self.max_level + 1):
            n = self.level_heads[l]
            while n:
                n.rank = 0
                n.label = None
                n = n.right

        # Base-level ranks
        n = self.level_heads[0].right
        while n:
            n.rank = 1
            n = n.right

        # Higher-level ranks
        for l in range(1, self.max_level + 1):
            n = self.level_heads[l].right
            while n:
                subtotal = 0
                d = n.down
                while d and (not n.right or d is not n.right.down):
                    subtotal += d.rank
                    d = d.right
                n.rank = subtotal
                n = n.right

        # Compute labels bottom-up
        for l in range(self.max_level + 1):
            nodes = []
            n = self.level_heads[l]
            while n:
                nodes.append(n)
                n = n.right
            for v in reversed(nodes):
                right_hash = v.right.label if (v.right and v.right.label) else b''
                child_hash = v.leaf_hash if v.level == 0 else (v.down.label if (v.down and v.down.label) else b'')
                ser = canonical_bytes(v.level) + canonical_bytes(v.rank) + canonical_bytes(child_hash) + canonical_bytes(right_hash)
                v.label = sha256(ser)

    def get_root(self):
        return self.head.label
    
    def get_actual_height(self):
        """Return the actual maximum level in use"""
        return self.actual_height

    # -----------------------------
    # Uniform O(log N) proof - TRUE O(log N) computation
    # This ensures proof size grows with N, not varies per node
    # -----------------------------
    def get_proof_chain(self, rank):
        if rank < 1 or rank > self.count:
            raise IndexError("rank out of range")

        proof = []
        remaining = rank
        
        # ALWAYS start from actual_height for uniform proof sizes
        # This makes proof size deterministic: O(log N) for the structure
        start_level = self.actual_height

        # Traverse from top to bottom using skip list search - O(log N)
        current = self.level_heads[start_level]
        leaf = None
        
        for level in range(start_level, -1, -1):
            # Move right at this level using ranks
            while current.right and current.right.rank < remaining:
                remaining -= current.right.rank
                current = current.right
            
            # Record this level's information (only if not at leaf)
            if level > 0:
                proof.append({
                    "level": level,
                    "rank": current.rank,
                    "right": current.right.label.hex() if current.right else ""
                })
            else:
                # At level 0, find the exact leaf node
                # After traversing down, 'current' is at level 0
                # Move right the remaining steps (should be minimal)
                while remaining > 1 and current.right:
                    remaining -= 1
                    current = current.right
                leaf = current
            
            # Move down to next level
            if current.down and level > 0:
                current = current.down

        # Add leaf information
        if leaf:
            proof.append({
                "level": 0,
                "key": leaf.key,
                "value": leaf.value,
                "leaf": leaf.leaf_hash.hex()
            })
        else:
            # Fallback (should not happen with correct rank logic)
            raise ValueError("Leaf node not found during traversal")

        return leaf.leaf_hash.hex(), proof

# ---------------------------------
# Verification (bottom-up, O(log N))
# ---------------------------------
def verify_chain(root_hash, leaf_val, proof):
    if not proof:
        return False, 0, []

    # Start with leaf hash
    leaf_entry = proof[-1]
    h = sha256(canonical_bytes(leaf_entry["key"]) + canonical_bytes(leaf_entry["value"]))
    total_bytes = len(canonical_bytes(leaf_entry["key"]) + canonical_bytes(leaf_entry["value"]))

    # Walk bottom-up through proof
    for entry in reversed(proof[:-1]):
        right_bytes = bytes.fromhex(entry.get("right", "")) if entry.get("right") else b''
        rank = entry.get("rank", 1)
        ser = canonical_bytes(entry["level"]) + canonical_bytes(rank) + canonical_bytes(h) + canonical_bytes(right_bytes)
        h = sha256(ser)
        total_bytes += len(ser)

    ok = (h == root_hash)
    return ok, total_bytes, []

# Demo
if __name__ == "__main__":
    if RANDOM_SEED is not None:
        random.seed(RANDOM_SEED)
    else:
        random.seed()

    asl = AuthSkipList(expected_size=N)
    print(f"Calculated max_level: {asl.max_level} (based on log2({N}) + margin)")

    keys = list(range(1000, 1000 + N))
    vals = list(range(1000, 1000 + N))

    print(f"Starting insertion of {N} elements (batch recompute every {BATCH_RECOMPUTE})...")
    t0_total = time.perf_counter()
    for i, (k, v) in enumerate(zip(keys, vals), start=1):
        asl.insert(k, v)
        if i % BATCH_RECOMPUTE == 0:
            asl.recompute()
    asl.recompute()
    t1_total = time.perf_counter()
    print(f"Insertion + final recompute done in {(t1_total - t0_total):.2f} sec")
    print(f"Actual skip list height achieved: {asl.get_actual_height()} levels")
    print(f"Expected proof size: {asl.get_actual_height() + 1} entries (levels 0-{asl.get_actual_height()})")

    root = asl.get_root()
    print("Root hash:", root.hex())

    csv_filename = f"asl_results_{N}nodes_logN.csv"
    print(f"Sampling every {SAMPLE_EVERY}th proof and writing results to {csv_filename} ...")

    with open(csv_filename, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=[
            "Node #", "Key", "Proof Computation Time (µs)",
            "Proof Verification Time (µs)",
            "Proof Gamma Storage (bytes)", "Proof Serialized Bytes",
            "Proof Length (levels)"
        ])
        writer.writeheader()

        for i in range(1, N + 1):
            if i % SAMPLE_EVERY != 0:
                continue
            t0 = time.perf_counter()
            leaf_val, proof = asl.get_proof_chain(i)
            t1 = time.perf_counter()
            proof_time = (t1 - t0) * 1e6

            t2 = time.perf_counter()
            ok, nbytes, gammas = verify_chain(root, leaf_val, proof)
            t3 = time.perf_counter()
            verify_time = (t3 - t2) * 1e6

            # Gamma storage is 32 bytes per level in proof
            proof_length = len(proof)
            gamma_storage = proof_length * 32

            writer.writerow({
                "Node #": i,
                "Key": proof[-1]["key"],
                "Proof Computation Time (µs)": proof_time,
                "Proof Verification Time (µs)": verify_time,
                "Proof Gamma Storage (bytes)": gamma_storage,
                "Proof Serialized Bytes": nbytes,
                "Proof Length (levels)": proof_length
            })

    print("Sampling complete. Building summary with pandas...")
    df = pd.read_csv(csv_filename)
    
    print("\n=== Proof Length Distribution ===")
    length_counts = df["Proof Length (levels)"].value_counts().sort_index()
    print(length_counts)
    if len(length_counts) == 1:
        print(f"✓ All proofs have uniform length: {length_counts.index[0]} levels")
    
    summary = pd.DataFrame({
        "Metric": [
            "Average Proof Computation Time (µs)",
            "Average Proof Verification Time (µs)",
            "Average Gamma Storage (bytes)",
            "Average Proof Serialized Bytes",
            "",
            "Largest Proof Computation Time (µs)",
            "Largest Proof Verification Time (µs)",
            "Largest Gamma Storage (bytes)",
            "Largest Proof Serialized Bytes",
            "",
            "Std Dev Proof Computation Time (µs)",
            "Std Dev Proof Verification Time (µs)",
            "Std Dev Gamma Storage (bytes)",
            "Std Dev Proof Serialized Bytes",
        ],
        "Value": [
            df["Proof Computation Time (µs)"].mean(),
            df["Proof Verification Time (µs)"].mean(),
            df["Proof Gamma Storage (bytes)"].mean(),
            df["Proof Serialized Bytes"].mean(),
            "",
            df["Proof Computation Time (µs)"].max(),
            df["Proof Verification Time (µs)"].max(),
            df["Proof Gamma Storage (bytes)"].max(),
            df["Proof Serialized Bytes"].max(),
            "",
            df["Proof Computation Time (µs)"].std(),
            df["Proof Verification Time (µs)"].std(),
            df["Proof Gamma Storage (bytes)"].std(),
            df["Proof Serialized Bytes"].std(),
        ]
    })

    summary.to_csv(f"Results_{N}nodes_logN.csv", index=False)
    print(f"\n=== Proof Performance Summary ({N} nodes, sampled) ===")
    print(f"Actual Skip List Height: {asl.get_actual_height()} levels")
    print(summary.to_string(index=False, justify="center", float_format=lambda x: f"{x:.2f}"))
